source('/Volumes/GoogleDrive/My Drive/Post-Doc/CHARM/LFS/LFS_fragment/figures/classifier/classifier_script.R')
library(dplyr)
library(ggplot2)
library(reshape2)
library(tidyr)
library(NMF)
library(Rtsne)
library(caret)
library(randomForest)
library(glmnet)
library(limma)
############################# Set kfolds split functions ###############################
SplitkFold <- function(Mat, Classes, K){
require(dplyr)
require(caret)
require(glmnet)
##Split into K folds
df <- data.frame(ID = rownames(Mat), Classes = Classes)
samples <- createFolds(df$Classes, k = K, list = TRUE, returnTrain=TRUE)
return(list(df = df, samples = samples))
}
SplitFunction <- function(Mat, Classes) {
require(dplyr)
require(caret)
require(glmnet)
##Split into training and test sets
df <- data.frame(ID = rownames(Mat), Classes = Classes)
samples <- createDataPartition(df$Classes, p = 0.8, times = 100)
return(list(df = df, samples = samples))
}
Features.CVparam <- trainControl(method = "repeatedcv", number = 10, repeats = 3, verboseIter = TRUE, returnData = FALSE, classProbs = TRUE, savePredictions = FALSE)
# Split the data into 10 folds
Splits10 <- list()
All.kFold <- list()
for (j in 1:100) {
# split the data for 100 times, result of each split is saved in Splits10
Splits10[[j]] <- SplitkFold(Data, y, 10)
#10-fold cross validation to calculate the probability (score) of each sample being cancer
kFold.list <- list()
for(i in 1:10) {
Indices = Splits10[[j]]$samples[[i]]
classes.df = Splits10[[j]]$df
TrainData <- Data[Indices,]
TrainPheno <- classes.df[Indices,]
TestData <- Data[!rownames(Data) %in% TrainPheno$ID,]
TestPheno <- classes.df%>%filter(!ID %in% TrainPheno$ID)
Model <- train(x = TrainData, y = TrainPheno, trControl = Features.CVparam, method = "rf" , tuneGrid = expand.grid(.mtry = mtry.val), metric = "Kappa")
Prediction.classProbs <- predict(Model, newdata = TestData, type = "prob")%>% data.frame
Prediction.classProbs$ActualClass <- TestPheno$Classes
Prediction.classProbs$PredictedClass <- predict(Model, newdata = TestData, type = "raw")
kFold.list[[i]] <- Prediction.classProbs
}
Predicted.classProbs <- kFold.list[[1]]$TestPred
for (i in 2:10) {
Predicted.classProbs <- bind_rows(Predicted.classProbs, kFold.list[[i]]$TestPred)
}
All.kFold[[j]] <- kFold.list
}
y <- factor(y, levels = c("negative", "positive"))
y
for (j in 1:100) {
# split the data for 100 times, result of each split is saved in Splits10
Splits10[[j]] <- SplitkFold(Data, y, 10)
#10-fold cross validation to calculate the probability (score) of each sample being cancer
kFold.list <- list()
for(i in 1:10) {
Indices = Splits10[[j]]$samples[[i]]
classes.df = Splits10[[j]]$df
TrainData <- Data[Indices,]
TrainPheno <- classes.df[Indices,]
TestData <- Data[!rownames(Data) %in% TrainPheno$ID,]
TestPheno <- classes.df%>%filter(!ID %in% TrainPheno$ID)
Model <- train(x = TrainData, y = TrainPheno, trControl = Features.CVparam, method = "rf" , tuneGrid = expand.grid(.mtry = mtry.val), metric = "Kappa")
Prediction.classProbs <- predict(Model, newdata = TestData, type = "prob")%>% data.frame
Prediction.classProbs$ActualClass <- TestPheno$Classes
Prediction.classProbs$PredictedClass <- predict(Model, newdata = TestData, type = "raw")
kFold.list[[i]] <- Prediction.classProbs
}
Predicted.classProbs <- kFold.list[[1]]$TestPred
for (i in 2:10) {
Predicted.classProbs <- bind_rows(Predicted.classProbs, kFold.list[[i]]$TestPred)
}
All.kFold[[j]] <- kFold.list
}
y <- as.data.frame(y)
View(y)
y
y <- c(rep("positive", sum(row.names(Data) %in% samples_neg$sWGS)))
y <- c(y, rep("negative", sum(!(row.names(Data) %in% samples_neg$sWGS))))
y <- factor(y, levels = c("negative", "positive"))
y <- as.data.frame(y)
for (j in 1:100) {
# split the data for 100 times, result of each split is saved in Splits10
Splits10[[j]] <- SplitkFold(Data, y, 10)
#10-fold cross validation to calculate the probability (score) of each sample being cancer
kFold.list <- list()
for(i in 1:10) {
Indices = Splits10[[j]]$samples[[i]]
classes.df = Splits10[[j]]$df
TrainData <- Data[Indices,]
TrainPheno <- classes.df[Indices,]
TestData <- Data[!rownames(Data) %in% TrainPheno$ID,]
TestPheno <- classes.df%>%filter(!ID %in% TrainPheno$ID)
Model <- train(x = TrainData, y = TrainPheno, trControl = Features.CVparam, method = "rf" , tuneGrid = expand.grid(.mtry = mtry.val), metric = "Kappa")
Prediction.classProbs <- predict(Model, newdata = TestData, type = "prob")%>% data.frame
Prediction.classProbs$ActualClass <- TestPheno$Classes
Prediction.classProbs$PredictedClass <- predict(Model, newdata = TestData, type = "raw")
kFold.list[[i]] <- Prediction.classProbs
}
Predicted.classProbs <- kFold.list[[1]]$TestPred
for (i in 2:10) {
Predicted.classProbs <- bind_rows(Predicted.classProbs, kFold.list[[i]]$TestPred)
}
All.kFold[[j]] <- kFold.list
}
# split the data for 100 times, result of each split is saved in Splits10
Splits10[[j]] <- SplitkFold(Data, y, 10)
View(Data)
df <- data.frame(ID = rownames(Data), Classes = y)
View(df)
k <- 10
samples <- createFolds(df$Classes, k = K, list = TRUE, returnTrain=TRUE)
K <- 10
samples <- createFolds(df$Classes, k = K, list = TRUE, returnTrain=TRUE)
source('/Volumes/GoogleDrive/My Drive/Post-Doc/CHARM/LFS/LFS_fragment/figures/classifier/classifier_script.R')
j <- 1
Mat <- Data
K = 10
Classes <- y
require(dplyr)
require(caret)
require(glmnet)
df <- data.frame(ID = rownames(Mat), Classes = Classes)
samples <- createFolds(df$Classes, k = K, list = TRUE, returnTrain=TRUE)
View(samples)
samples[["Fold01"]]
return(list(df = df, samples = samples))
# split the data for 100 times, result of each split is saved in Splits10
Splits10[[j]] <- SplitkFold(Data, y, 10)
SplitkFold <- function(Mat, Classes, K){
require(dplyr)
require(caret)
require(glmnet)
##Split into K folds
df <- data.frame(ID = rownames(Mat), Classes = Classes)
samples <- createFolds(df$Classes, k = K, list = TRUE, returnTrain=TRUE)
return(list(df = df, samples = samples))
}
SplitFunction <- function(Mat, Classes) {
require(dplyr)
require(caret)
require(glmnet)
##Split into training and test sets
df <- data.frame(ID = rownames(Mat), Classes = Classes)
samples <- createDataPartition(df$Classes, p = 0.8, times = 100)
return(list(df = df, samples = samples))
}
# split the data for 100 times, result of each split is saved in Splits10
Splits10[[j]] <- SplitkFold(Data, y, 10)
# Split the data into 10 folds
Splits10 <- list()
All.kFold <- list()
# split the data for 100 times, result of each split is saved in Splits10
Splits10[[j]] <- SplitkFold(Data, y, 10)
#10-fold cross validation to calculate the probability (score) of each sample being cancer
kFold.list <- list()
for(i in 1:10) {
Indices = Splits10[[j]]$samples[[i]]
classes.df = Splits10[[j]]$df
TrainData <- Data[Indices,]
TrainPheno <- classes.df[Indices,]
TestData <- Data[!rownames(Data) %in% TrainPheno$ID,]
TestPheno <- classes.df%>%filter(!ID %in% TrainPheno$ID)
Model <- train(x = TrainData, y = TrainPheno, trControl = Features.CVparam, method = "rf" , tuneGrid = expand.grid(.mtry = mtry.val), metric = "Kappa")
Prediction.classProbs <- predict(Model, newdata = TestData, type = "prob")%>% data.frame
Prediction.classProbs$ActualClass <- TestPheno$Classes
Prediction.classProbs$PredictedClass <- predict(Model, newdata = TestData, type = "raw")
kFold.list[[i]] <- Prediction.classProbs
}
i <- 1
Indices = Splits10[[j]]$samples[[i]]
classes.df = Splits10[[j]]$df
View(classes.df)
View(Splits10)
TrainData <- Data[Indices,]
TrainPheno <- classes.df[Indices,]
TestData <- Data[!rownames(Data) %in% TrainPheno$ID,]
TestPheno <- classes.df%>%filter(!ID %in% TrainPheno$ID)
View(TrainData)
View(TrainPheno)
Model <- train(x = TrainData, y = TrainPheno, trControl = Features.CVparam, method = "rf" , tuneGrid = expand.grid(.mtry = mtry.val), metric = "Kappa")
source('/Volumes/GoogleDrive/My Drive/Post-Doc/CHARM/LFS/LFS_fragment/figures/classifier/classifier_script.R')
source('/Volumes/GoogleDrive/My Drive/Post-Doc/CHARM/LFS/LFS_fragment/figures/classifier/FuncClassifier.R')
source('/Volumes/GoogleDrive/My Drive/Post-Doc/CHARM/LFS/LFS_fragment/figures/classifier/classifier_script.R')
Features.CVparam <- trainControl(method = "repeatedcv", number = 10, repeats = 3, verboseIter = TRUE, returnData = FALSE, classProbs = TRUE, savePredictions = FALSE)
# Split the data into 10 folds
Splits10 <- list()
All.kFold <- list()
for (j in 1:100) {
# split the data for 100 times, result of each split is saved in Splits10
Splits10[[j]] <- SplitkFold(Data, y, 10)
#10-fold cross validation to calculate the probability (score) of each sample being cancer
kFold.list <- list()
for(i in 1:10) {
Indices = Splits10[[j]]$samples[[i]]
classes.df = Splits10[[j]]$df
TrainData <- Data[Indices,]
TrainPheno <- classes.df[Indices,]
TestData <- Data[!rownames(Data) %in% TrainPheno$ID,]
TestPheno <- classes.df%>%filter(!ID %in% TrainPheno$ID)
Model <- train(x = TrainData, y = TrainPheno, trControl = Features.CVparam, method = "rf" , tuneGrid = expand.grid(.mtry = mtry.val), metric = "Kappa")
Prediction.classProbs <- predict(Model, newdata = TestData, type = "prob")%>% data.frame
Prediction.classProbs$ActualClass <- TestPheno$Classes
Prediction.classProbs$PredictedClass <- predict(Model, newdata = TestData, type = "raw")
kFold.list[[i]] <- Prediction.classProbs
}
Predicted.classProbs <- kFold.list[[1]]$TestPred
for (i in 2:10) {
Predicted.classProbs <- bind_rows(Predicted.classProbs, kFold.list[[i]]$TestPred)
}
All.kFold[[j]] <- kFold.list
}
# split the data for 100 times, result of each split is saved in Splits10
Splits10[[j]] <- SplitkFold(Data, y, 10)
#10-fold cross validation to calculate the probability (score) of each sample being cancer
kFold.list <- list()
# split the data for 100 times, result of each split is saved in Splits10
Splits10[[j]] <- SplitkFold(Data, y, 10)
# Split the data into 10 folds
Splits10 <- list()
All.kFold <- list()
# split the data for 100 times, result of each split is saved in Splits10
Splits10[[j]] <- SplitkFold(Data, y, 10)
y
y <- c(rep(1, sum(row.names(Data) %in% samples_neg$sWGS)))
y <- c(y, rep(0, sum(!(row.names(Data) %in% samples_neg$sWGS))))
# split the data for 100 times, result of each split is saved in Splits10
Splits10[[j]] <- SplitkFold(Data, y, 10)
#10-fold cross validation to calculate the probability (score) of each sample being cancer
kFold.list <- list()
for(i in 1:10) {
Indices = Splits10[[j]]$samples[[i]]
classes.df = Splits10[[j]]$df
TrainData <- Data[Indices,]
TrainPheno <- classes.df[Indices,]
TestData <- Data[!rownames(Data) %in% TrainPheno$ID,]
TestPheno <- classes.df%>%filter(!ID %in% TrainPheno$ID)
Model <- train(x = TrainData, y = TrainPheno, trControl = Features.CVparam, method = "rf" , tuneGrid = expand.grid(.mtry = mtry.val), metric = "Kappa")
Prediction.classProbs <- predict(Model, newdata = TestData, type = "prob")%>% data.frame
Prediction.classProbs$ActualClass <- TestPheno$Classes
Prediction.classProbs$PredictedClass <- predict(Model, newdata = TestData, type = "raw")
kFold.list[[i]] <- Prediction.classProbs
}
TrainPheno$Classes
class(TrainPheno$Classes)
Indices = Splits10[[j]]$samples[[i]]
classes.df = Splits10[[j]]$df
TrainData <- Data[Indices,]
TrainPheno <- classes.df[Indices,]
TestData <- Data[!rownames(Data) %in% TrainPheno$ID,]
TestPheno <- classes.df%>%filter(!ID %in% TrainPheno$ID)
Model <- train(x = TrainData, y = TrainPheno$Classes, trControl = Features.CVparam, method = "rf" , tuneGrid = expand.grid(.mtry = mtry.val), metric = "Kappa")
y <- c(rep("positive", sum(row.names(Data) %in% samples_neg$sWGS)))
y <- c(y, rep("negative", sum(!(row.names(Data) %in% samples_neg$sWGS))))
y <- factor(y, levels = c("negative", "positive"))
Indices = Splits10[[j]]$samples[[i]]
classes.df = Splits10[[j]]$df
TrainData <- Data[Indices,]
TrainPheno <- classes.df[Indices,]
TestData <- Data[!rownames(Data) %in% TrainPheno$ID,]
TestPheno <- classes.df%>%filter(!ID %in% TrainPheno$ID)
Model <- train(x = TrainData, y = TrainPheno$Classes, trControl = Features.CVparam, method = "rf", tuneGrid = expand.grid(.mtry = mtry.val), metric = "Kappa")
View(TestPheno)
# split the data for 100 times, result of each split is saved in Splits10
Splits10[[j]] <- SplitkFold(Data, y, 10)
#10-fold cross validation to calculate the probability (score) of each sample being cancer
kFold.list <- list()
Indices = Splits10[[j]]$samples[[i]]
classes.df = Splits10[[j]]$df
TrainData <- Data[Indices,]
TrainPheno <- classes.df[Indices,]
TestData <- Data[!rownames(Data) %in% TrainPheno$ID,]
TestPheno <- classes.df%>%filter(!ID %in% TrainPheno$ID)
Model <- train(x = TrainData, y = TrainPheno$Classes, trControl = Features.CVparam, method = "rf", tuneGrid = expand.grid(.mtry = mtry.val), metric = "Kappa")
mtry.val <- ncol(TrainData)/3
Model <- train(x = TrainData, y = TrainPheno$Classes, trControl = Features.CVparam, method = "rf", tuneGrid = expand.grid(.mtry = mtry.val), metric = "Kappa")
Prediction.classProbs <- predict(Model, newdata = TestData, type = "prob")%>% data.frame
Prediction.classProbs$ActualClass <- TestPheno$Classes
Prediction.classProbs$PredictedClass <- predict(Model, newdata = TestData, type = "raw")
kFold.list[[i]] <- Prediction.classProbs
View(kFold.list)
kFold.list[[1]][["positive"]]
Predicted.classProbs <- kFold.list[[1]]$TestPred
View(Prediction.classProbs)
Model
All.kFold[[j]] <- kFold.list
View(All.kFold)
SplitkFold <- function(Mat, Classes, K){
require(dplyr)
require(caret)
require(glmnet)
##Split into K folds
df <- data.frame(ID = rownames(Mat), Classes = Classes)
samples <- createFolds(df$Classes, k = K, list = TRUE, returnTrain=TRUE)
return(list(df = df, samples = samples))
}
SplitFunction <- function(Mat, Classes) {
require(dplyr)
require(caret)
require(glmnet)
##Split into training and test sets
df <- data.frame(ID = rownames(Mat), Classes = Classes)
samples <- createDataPartition(df$Classes, p = 0.8, times = 100)
return(list(df = df, samples = samples))
}
source('/Volumes/GoogleDrive/My Drive/Post-Doc/CHARM/LFS/LFS_fragment/figures/classifier/classifier_script.R')
Features.CVparam <- trainControl(method = "repeatedcv", number = 10, repeats = 3, verboseIter = TRUE, returnData = FALSE, classProbs = TRUE, savePredictions = FALSE)
# Split the data into 10 folds
Splits10 <- list()
All.kFold <- list()
for (j in 1:10) {
# split the data for 100 times, result of each split is saved in Splits10
Splits10[[j]] <- SplitkFold(Data, y, 10)
#10-fold cross validation to calculate the probability (score) of each sample being cancer
kFold.list <- list()
for(i in 1:10) {
Indices = Splits10[[j]]$samples[[i]]
classes.df = Splits10[[j]]$df
TrainData <- Data[Indices,]
TrainPheno <- classes.df[Indices,]
TestData <- Data[!rownames(Data) %in% TrainPheno$ID,]
TestPheno <- classes.df%>%filter(!ID %in% TrainPheno$ID)
mtry.val <- ncol(TrainData)/3
Model <- train(x = TrainData, y = TrainPheno$Classes, trControl = Features.CVparam, method = "rf", tuneGrid = expand.grid(.mtry = mtry.val), metric = "Kappa")
Prediction.classProbs <- predict(Model, newdata = TestData, type = "prob")%>% data.frame
Prediction.classProbs$ActualClass <- TestPheno$Classes
Prediction.classProbs$PredictedClass <- predict(Model, newdata = TestData, type = "raw")
kFold.list[[i]] <- Prediction.classProbs
}
Predicted.classProbs <- kFold.list[[1]]$TestPred
for (i in 2:10) {
Predicted.classProbs <- bind_rows(Predicted.classProbs, kFold.list[[i]]$TestPred)
}
All.kFold[[j]] <- kFold.list
}
View(All.kFold)
outcomes <- do.call("rbind", All.kFold)
View(outcomes)
View(outcomes[[1]][[1]])
length(All.kFold)
outcomes <- All.kFold
for (k in c(1:length(outcomes))) {
outcomes[[k]] <- do.call("rbind", outcomes[k])
}
View(outcomes)
outcomes <- unlist(All.kFold, recursive = FALSE)
View(outcomes)
outcomes <- do.call("rbind", outcomes)
View(outcomes)
View(outcomes)
### Make LFS positive vs negative
Data <- data_freq[row.names(data_freq) %in% samples$sWGS, ]
### Make LFS positive vs negative
Data <- data_freq[row.names(data_freq) %in% data_samples$sWGS, ]
y <- data_samples$cancer_status
y
class(y)
y <- factor(y, levels = "negative", "positive")
confusionMatrix(outcomes$ActualClass, outcomes$PredictedClass)
